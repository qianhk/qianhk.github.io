<!DOCTYPE html>
<html lang="zh-cmn-Hans">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>钱凯凯</title>
  
  
  <!--link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css"-->
  <link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css">
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
<div class="Shell">
    <aside class='SideBar'>
    <section class='avatar' style="background-image: url()">
        <div class='av-pic' style="background-image: url(/assets/avatar.jpg)">
        </div>
    </section>
    <section class='menu'>
        <div>钱凯凯</div>
        
            <div>钱凯凯的博客</div>
        
        <ul>
          
            <a href="/" class="Btn">
              <li>Home</li>
            </a>  
          
            <a href="/archives/" class="Btn">
              <li>Archive</li>
            </a>  
          
        </ul>
    </section>
    <section class="media">
        
            
                <a href="https://github.com/qianhk">
                    <img src="/assets/github.svg" />
                </a>
            
        
    </section>
</aside>

    <div class="container">
        <div data-pager-shell>
            <ul class="Index">
  
    <header class='PageTitle'>
        <h1>{ Tensorflow }</h1>
    </header>
  
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2018/05/客户端码农学习ML-使用LinearRegressor实现线性回归/">客户端码农学习ML —— 使用LinearRegressor实现线性回归</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2018-05-12T15:17:18.000Z" itemprop="datePublished">
    2018-05-12
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/AI/">AI</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Linear-Regression/">Linear Regression</a> }
  </li>


  </ul>
  
  
</div>

    </header>
    <div>
      
        <p>最近看了<a href="https://developers.google.cn/machine-learning/crash-course/prereqs-and-prework" target="_blank" rel="noopener">Google官方机器学习教程</a>，跟着练习了部分示例，其中<a href="https://colab.research.google.com/notebooks/mlcc/first_steps_with_tensor_flow.ipynb?hl=zh-cn" target="_blank" rel="noopener">《使用 TensorFlow 的起始步骤》</a>采用了LinearRegressor配合Pandas来进行线性回归训练。</p>
<p>于是使用两者重新写了一个版本的线性回归训练，数据也从之前python直接生成模拟数据改成了从csv文件读取，而csv文件来源于Excel: A列的100行等于1至100的序列， B=A*5+50+RANDBETWEEN(-10, 10)。</p>
<h3 id="读取数据集及特征准备"><a href="#读取数据集及特征准备" class="headerlink" title="读取数据集及特征准备"></a>读取数据集及特征准备</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn import metrics</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow.python.data import Dataset</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line">linear_dataframe = pd.read_csv(&quot;../data/linear_data.csv&quot;, sep=&quot;,&quot;)</span><br><span class="line"></span><br><span class="line">print(&apos;linear_dataframe.describe()=%s\n&apos; % linear_dataframe.describe())</span><br><span class="line"></span><br><span class="line">x_series = linear_dataframe[&quot;x&quot;].apply(lambda x: max(x, -10000))</span><br><span class="line">my_feature_dataframe = linear_dataframe[[&quot;x&quot;]]</span><br><span class="line"></span><br><span class="line">x_feature_column = tf.feature_column.numeric_column(&quot;x&quot;)</span><br><span class="line">feature_columns = [x_feature_column]</span><br><span class="line"></span><br><span class="line">target_series = linear_dataframe[&quot;y&quot;]</span><br></pre></td></tr></table></figure>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001)</span><br><span class="line"># my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)</span><br><span class="line"></span><br><span class="line">linear_regressor = tf.estimator.LinearRegressor(feature_columns=feature_columns, optimizer=my_optimizer)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def my_input_fn(feature_dataframe, target_series, batch_size=1, shuffle=True, num_epochs=None):</span><br><span class="line">    features = &#123;key: np.array(value) for key, value in dict(feature_dataframe).items()&#125;</span><br><span class="line"></span><br><span class="line">    ds = Dataset.from_tensor_slices((features, target_series))</span><br><span class="line">    ds = ds.batch(batch_size).repeat(num_epochs)</span><br><span class="line"></span><br><span class="line">    if shuffle:</span><br><span class="line">        ds = ds.shuffle(buffer_size=10000)</span><br><span class="line"></span><br><span class="line">    features, labels = ds.make_one_shot_iterator().get_next()</span><br><span class="line">    return features, labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">_ = linear_regressor.train(input_fn=lambda: my_input_fn(my_feature_dataframe, target_series), steps=2000)</span><br></pre></td></tr></table></figure>
<h3 id="结果评估"><a href="#结果评估" class="headerlink" title="结果评估"></a>结果评估</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">predict_input_fn = lambda: my_input_fn(my_feature_dataframe, target_series, num_epochs=1, shuffle=False)</span><br><span class="line"></span><br><span class="line">predictions = linear_regressor.predict(input_fn=predict_input_fn)</span><br><span class="line">predictions = np.array([item[&apos;predictions&apos;][0] for item in predictions])</span><br><span class="line"></span><br><span class="line">mean_squared_error = metrics.mean_squared_error(predictions, target_series)</span><br><span class="line">root_mean_squared_error = math.sqrt(mean_squared_error)</span><br><span class="line">print(&quot;Mean Squared Error (on training data): %0.3f&quot; % mean_squared_error)</span><br><span class="line">print(&quot;Root Mean Squared Error (on training data): %0.3f&quot; % root_mean_squared_error)</span><br><span class="line"></span><br><span class="line">min_y_value = target_series.min()</span><br><span class="line">max_y_value = target_series.max()</span><br><span class="line">min_max_difference = max_y_value - min_y_value</span><br><span class="line"></span><br><span class="line">print(&quot;Min. x Value: %0.3f&quot; % min_y_value)</span><br><span class="line">print(&quot;Max. x: %0.3f&quot; % max_y_value)</span><br><span class="line">print(&quot;Difference between Min. and Max.: %0.3f&quot; % min_max_difference)</span><br><span class="line">print(&quot;Root Mean Squared Error: %0.3f&quot; % root_mean_squared_error)</span><br><span class="line"></span><br><span class="line">weight = linear_regressor.get_variable_value(&apos;linear/linear_model/x/weights&apos;)</span><br><span class="line">bias = linear_regressor.get_variable_value(&apos;linear/linear_model/bias_weights&apos;)</span><br><span class="line">print(&apos;\n weight=%s  bias=%s&apos; % (weight, bias))</span><br><span class="line">[[_w]] = weight</span><br><span class="line">[_b] = bias</span><br><span class="line"></span><br><span class="line">result_dataframe = pd.DataFrame()</span><br><span class="line">result_dataframe[&quot;predictions&quot;] = pd.Series(predictions)</span><br><span class="line">result_dataframe[&quot;targets&quot;] = target_series</span><br><span class="line">print(&apos;\nresult dataframe:\n%s&apos; % result_dataframe.describe())</span><br></pre></td></tr></table></figure>
<h3 id="结果可视化"><a href="#结果可视化" class="headerlink" title="结果可视化"></a>结果可视化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def show_visualization_data(x_data_array, y_data_array, w, b, loss_vec, title=None):</span><br><span class="line">    best_fit = []</span><br><span class="line">    for x in x_data_array:</span><br><span class="line">        best_fit.append(w * x + b)</span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line"></span><br><span class="line">    if title is not None:</span><br><span class="line">        plt.title(title)</span><br><span class="line"></span><br><span class="line">    ax = plt.subplot(121)</span><br><span class="line">    ax.scatter(x_data_array, y_data_array, color=&apos;y&apos;, label=&quot;样本&quot;, linewidths=0.5)</span><br><span class="line">    ax.plot(x_data_array, best_fit, color=&apos;b&apos;, linewidth=2)</span><br><span class="line"></span><br><span class="line">    if loss_vec is not None:</span><br><span class="line">        ax = plt.subplot(122)</span><br><span class="line">        ax.plot(loss_vec, color=&apos;g&apos;, linewidth=1)</span><br><span class="line">        ax.set_ylim(0, 1000)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">show_visualization_data(x_series, target_series, _w, _b, None, title=&apos;Pandas&apos;)</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://developers.google.cn/machine-learning/crash-course/prereqs-and-prework" target="_blank" rel="noopener">https://developers.google.cn/machine-learning/crash-course/prereqs-and-prework</a></p>
<p><a href="https://colab.research.google.com/notebooks/mlcc/first_steps_with_tensor_flow.ipynb?hl=zh-cn" target="_blank" rel="noopener">https://colab.research.google.com/notebooks/mlcc/first_steps_with_tensor_flow.ipynb?hl=zh-cn</a></p>
<h1 id=""><a href="#" class="headerlink" title="　"></a>　</h1><p>本文首发于<a href="http://qianhk.com">钱凯凯的博客</a> : <a href="http://qianhk.com/2018/02/客户端码农学习ML-使用LinearRegressor实现线性回归/">http://qianhk.com/2018/02/客户端码农学习ML-使用LinearRegressor实现线性回归/</a></p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2018/02/客户端码农学习ML-用TensorFlow实现线性回归算法/">客户端码农学习ML —— 用TensorFlow实现线性回归算法</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2018-02-27T14:26:50.000Z" itemprop="datePublished">
    2018-02-27
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/AI/">AI</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>


  </ul>
  
  
</div>

    </header>
    <div>
      
        <h1 id="线性回归（Linear-Regression）"><a href="#线性回归（Linear-Regression）" class="headerlink" title="线性回归（Linear Regression）"></a>线性回归（Linear Regression）</h1><p>线性回归算法是机器学习、统计分析中重要的算法之一，也是常用的相对简单的算法。</p>
<p>微信小游戏跳一跳某辅助程序<a href="https://github.com/wangshub/wechat_jump_game" target="_blank" rel="noopener">wechat jump game</a>，之前要事先根据屏幕尺寸填写一个按压时间与弹跳距离的比例经验值并不断人为调整，后来可通过此算法拟合按压时间与弹跳距离了, <a href="https://github.com/wangshub/wechat_jump_game/pull/825" target="_blank" rel="noopener">Pull Request在此</a>。</p>
<p>给定由d个属性描述的点集X=(x<sub>1</sub>;x<sub>2</sub>;…;x<sub>d</sub>), 线性模型试图学得一个通过属性的线性组合来进行预测的函数，即&fnof;(x)=w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + … + w<sub>d</sub>x<sub>d</sub> + b，知道w和b后就能确定模型。</p>
        
          <div class="more-link">
            <a href="/2018/02/客户端码农学习ML-用TensorFlow实现线性回归算法/#more">阅读更多 »</a>
          </div>
        
      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/2018/02/客户端码农学习ML-工具框架Tensorflow/">客户端码农学习ML —— 工具框架Tensorflow及Android、iOS上初步实验</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2018-02-21T03:06:50.000Z" itemprop="datePublished">
    2018-02-21
  </time>
  
  | 
  <ul>
    
  <li class="meta-text">
  { <a href="/tags/AI/">AI</a> }
  </li>

  <li class="meta-text">
  { <a href="/tags/Tensorflow/">Tensorflow</a> }
  </li>


  </ul>
  
  
</div>

    </header>
    <div>
      
        <p>与其上来就学习相对枯燥易让人放弃的数学，不如先做几个例子并在Android、iOS上初步实验熟悉下整个操作流程，通过实战激发下兴趣。</p>
<h2 id="开发环境准备"><a href="#开发环境准备" class="headerlink" title="开发环境准备"></a>开发环境准备</h2><p>首先安装Python，推荐Python3，装好后别忘了设置下载源镜像，不然安装各种包的时候下载速度很感人。</p>
<p>新建文件：~/.pip/pip.conf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">[install]</span><br><span class="line">use-mirrors = true</span><br><span class="line">mirrors = https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>
<p>再安装Numpy、SciPy、Pandas、Matplotlib、Pil、TensorFlow 、scikit-learn等库，都是深度学习不可缺少的。</p>
        
          <div class="more-link">
            <a href="/2018/02/客户端码农学习ML-工具框架Tensorflow/#more">阅读更多 »</a>
          </div>
        
      
    </div>
</article>

    </li>
  
</ul>



            <footer>
    <div>© 2016 - qianhk </div>
    <div>
    Powered by Hexo
    </div>
</footer>

        </div>
    </div>
</div>
<script src="/js/pager/dist/singlepager.js"></script>
<script>
var sp = new Pager('data-pager-shell')

</script>
</body>
</html>